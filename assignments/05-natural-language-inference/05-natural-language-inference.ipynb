{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A5: Natural Language Inference using Neural Networks\n",
    "\n",
    "Adam Ek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lab is an exploration and learning exercise to be done in a group and also in discussion with the teachers and other students.\n",
    "\n",
    "Write all your answers and the code in the appropriate boxes below.\n",
    "\n",
    "\n",
    "In this lab we will work with neural networks for natural language inference. Our task is: given a premise sentence P and hypothesis H, what entailment relationship holds between them? Is H entailed by P, contradicted by P or neutral towards P?\n",
    "\n",
    "Given a sentence P, if H definitely describe something true given P then it is an **entailment**. If H describe something that's *maybe* true given P, it's **neutral**, and if H describe something that's definitely *false* given P it's a **contradiction**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will explore natural language inference using neural networks on the SNLI dataset, described in [1]. The dataset can be downloaded [here](https://nlp.stanford.edu/projects/snli/). We prepared a \"simplified\" version, with only the relevant columns in `simple_snli_1.0.zip`.\n",
    "\n",
    "The (simplified) data is organized as follows (tab-separated values):\n",
    "* Column 1: Premise\n",
    "* Column 2: Hypothesis\n",
    "* Column 3: Relation\n",
    "\n",
    "Like in the previous lab, we'll use torchtext to build a dataloader. You can essentially do the same thing as you did in the last lab, but with our new dataset. **[1 mark]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.4 MB)\n",
      "     |████████████████████████████████| 26.4 MB 272 kB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /usr/local/lib64/python3.10/site-packages (from gensim) (1.23.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/gussodato@GU.GU.SE/.local/lib/python3.10/site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib64/python3.10/site-packages (from gensim) (1.9.2)\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-4.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from gensim.utils import tokenize\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pickle\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = torch.device('cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-05-29 12:42:54--  https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 94550081 (90M) [application/zip]\n",
      "Saving to: ‘snli_1.0.zip’\n",
      "\n",
      "snli_1.0.zip        100%[===================>]  90.17M  17.3MB/s    in 10s     \n",
      "\n",
      "2023-05-29 12:43:06 (8.84 MB/s) - ‘snli_1.0.zip’ saved [94550081/94550081]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  snli_1.0.zip\n",
      "   creating: snli_1.0/\n",
      "  inflating: snli_1.0/.DS_Store      \n",
      "   creating: __MACOSX/\n",
      "   creating: __MACOSX/snli_1.0/\n",
      "  inflating: __MACOSX/snli_1.0/._.DS_Store  \n",
      " extracting: snli_1.0/Icon           \n",
      "  inflating: __MACOSX/snli_1.0/._Icon  \n",
      "  inflating: snli_1.0/README.txt     \n",
      "  inflating: __MACOSX/snli_1.0/._README.txt  \n",
      "  inflating: snli_1.0/snli_1.0_dev.jsonl  \n",
      "  inflating: snli_1.0/snli_1.0_dev.txt  \n",
      "  inflating: snli_1.0/snli_1.0_test.jsonl  \n",
      "  inflating: snli_1.0/snli_1.0_test.txt  \n",
      "  inflating: snli_1.0/snli_1.0_train.jsonl  \n",
      "  inflating: snli_1.0/snli_1.0_train.txt  \n",
      "  inflating: __MACOSX/._snli_1.0     \n"
     ]
    }
   ],
   "source": [
    "!unzip snli_1.0.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neutral', 'contradiction', 'entailment', '-']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./snli_1.0/snli_1.0_test.txt', sep='\\t')\n",
    "test = df[['sentence1', 'sentence2', 'gold_label']]\n",
    "list(tokenize(test['sentence1'][0]))\n",
    "list(set(test['gold_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './snli_1.0/snli_1.0_train.txt'\n",
    "dev_path = './snli_1.0/snli_1.0_dev.txt'\n",
    "test_path = './snli_1.0/snli_1.0_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.read_csv('./snli_1.0/snli_1.0_train.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550152"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traindf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0014268783899722259"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(785)/550152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1_binary_parse</th>\n",
       "      <th>sentence2_binary_parse</th>\n",
       "      <th>sentence1_parse</th>\n",
       "      <th>sentence2_parse</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>captionID</th>\n",
       "      <th>pairID</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>label3</th>\n",
       "      <th>label4</th>\n",
       "      <th>label5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>-</td>\n",
       "      <td>( ( ( A ( small group ) ) ( of church-goers ) ...</td>\n",
       "      <td>( ( A choir ) ( ( performs ( in ( front ( of (...</td>\n",
       "      <td>(ROOT (S (NP (NP (DT A) (JJ small) (NN group))...</td>\n",
       "      <td>(ROOT (S (NP (DT A) (NN choir)) (VP (VBZ perfo...</td>\n",
       "      <td>A small group of church-goers watch a choir pr...</td>\n",
       "      <td>A choir performs in front of packed crowd.</td>\n",
       "      <td>2677109430.jpg#2</td>\n",
       "      <td>2677109430.jpg#2r1c</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>-</td>\n",
       "      <td>( ( ( A woman ) ( wearing ( a ( pink hat ) ) )...</td>\n",
       "      <td>( ( The woman ) ( ( is ( wearing clothes ) ) ....</td>\n",
       "      <td>(ROOT (S (NP (NP (DT A) (NN woman)) (VP (VBG w...</td>\n",
       "      <td>(ROOT (S (NP (DT The) (NN woman)) (VP (VBZ is)...</td>\n",
       "      <td>A woman wearing a pink hat is looking at a pin...</td>\n",
       "      <td>The woman is wearing clothes.</td>\n",
       "      <td>226630666.jpg#1</td>\n",
       "      <td>226630666.jpg#1r1e</td>\n",
       "      <td>entailment</td>\n",
       "      <td>entailment</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>-</td>\n",
       "      <td>( man ( in ( ( red ( canada shirt ) ) ( standi...</td>\n",
       "      <td>( ( Man standing ) ( with ( ( three men ) ( in...</td>\n",
       "      <td>(ROOT (NP (NP (NN man)) (PP (IN in) (NP (NP (J...</td>\n",
       "      <td>(ROOT (NP (NP (NN Man) (NN standing)) (PP (IN ...</td>\n",
       "      <td>man in red canada shirt standing with three me...</td>\n",
       "      <td>Man standing with three men in army uniform ne...</td>\n",
       "      <td>179172576.jpg#3</td>\n",
       "      <td>179172576.jpg#3r1n</td>\n",
       "      <td>neutral</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>entailment</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>-</td>\n",
       "      <td>( ( ( ( A man ) ( in ( a ( white jacket ) ) ) ...</td>\n",
       "      <td>( ( The man ) ( ( was ( ( playing crochet ) ( ...</td>\n",
       "      <td>(ROOT (NP (NP (NP (DT A) (NN man)) (PP (IN in)...</td>\n",
       "      <td>(ROOT (S (NP (DT The) (NN man)) (VP (VBD was) ...</td>\n",
       "      <td>A man in a white jacket standing in front of a...</td>\n",
       "      <td>The man was playing crochet with the two women.</td>\n",
       "      <td>4926115712.jpg#0</td>\n",
       "      <td>4926115712.jpg#0r1n</td>\n",
       "      <td>neutral</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>neutral</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>-</td>\n",
       "      <td>( ( ( A ( swimmer 's ) ) hand ) ( ( is ( taken...</td>\n",
       "      <td>( ( The swimmer ) ( ( is female ) . ) )</td>\n",
       "      <td>(ROOT (S (NP (NP (DT A) (NN swimmer) (POS 's))...</td>\n",
       "      <td>(ROOT (S (NP (DT The) (NN swimmer)) (VP (VBZ i...</td>\n",
       "      <td>A swimmer's hand is taken as he gets out of th...</td>\n",
       "      <td>The swimmer is female.</td>\n",
       "      <td>7249180494.jpg#2</td>\n",
       "      <td>7249180494.jpg#2r1n</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548159</th>\n",
       "      <td>-</td>\n",
       "      <td>( ( Four people ) ( ( are ( ( selecting foods ...</td>\n",
       "      <td>( ( The people ) ( ( are ( looking ( at ( ( th...</td>\n",
       "      <td>(ROOT (S (NP (CD Four) (NNS people)) (VP (VBP ...</td>\n",
       "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
       "      <td>Four people are selecting foods from the buffet.</td>\n",
       "      <td>The people are looking at the things being ser...</td>\n",
       "      <td>307694396.jpg#1</td>\n",
       "      <td>307694396.jpg#1r1e</td>\n",
       "      <td>entailment</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>neutral</td>\n",
       "      <td>entailment</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548466</th>\n",
       "      <td>-</td>\n",
       "      <td>( ( An ( outdoor ( market vendor ) ) ) ( ( ( r...</td>\n",
       "      <td>( ( A woman ) ( ( ( prepares ( for ( ( her day...</td>\n",
       "      <td>(ROOT (S (NP (DT An) (JJ outdoor) (NN market) ...</td>\n",
       "      <td>(ROOT (S (NP (DT A) (NN woman)) (VP (VBZ prepa...</td>\n",
       "      <td>An outdoor market vendor reaches up with a pol...</td>\n",
       "      <td>A woman prepares for her day of business by ge...</td>\n",
       "      <td>4921374490.jpg#2</td>\n",
       "      <td>4921374490.jpg#2r1n</td>\n",
       "      <td>neutral</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>entailment</td>\n",
       "      <td>neutral</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548920</th>\n",
       "      <td>-</td>\n",
       "      <td>( ( One ( black dog ) ) ( ( chases ( ( ( anoth...</td>\n",
       "      <td>( There ( ( is ( ( grass ( on ( a ( road event...</td>\n",
       "      <td>(ROOT (S (NP (CD One) (JJ black) (NN dog)) (VP...</td>\n",
       "      <td>(ROOT (S (NP (EX There)) (VP (VBZ is) (NP (NP ...</td>\n",
       "      <td>One black dog chases another on grass nearby a...</td>\n",
       "      <td>There is grass on a road eventhough it snowed ...</td>\n",
       "      <td>2281075738.jpg#0</td>\n",
       "      <td>2281075738.jpg#0r1e</td>\n",
       "      <td>entailment</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>entailment</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549427</th>\n",
       "      <td>-</td>\n",
       "      <td>( ( The couple ) ( ( pauses ( atop ( a ( rocky...</td>\n",
       "      <td>( ( The couple ) ( ( is ( walking ( on ( a ( r...</td>\n",
       "      <td>(ROOT (S (NP (DT The) (NN couple)) (VP (VBZ pa...</td>\n",
       "      <td>(ROOT (S (NP (DT The) (NN couple)) (VP (VBZ is...</td>\n",
       "      <td>The couple pauses atop a rocky overlook.</td>\n",
       "      <td>The couple is walking on a rockky overlook.</td>\n",
       "      <td>508958120.jpg#4</td>\n",
       "      <td>508958120.jpg#4r1n</td>\n",
       "      <td>neutral</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>entailment</td>\n",
       "      <td>entailment</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549681</th>\n",
       "      <td>-</td>\n",
       "      <td>( ( A girl ) ( ( is ( playing ( with ( toys ( ...</td>\n",
       "      <td>( ( A girl ) ( ( is ( taking ( a bath ) ) ) . ) )</td>\n",
       "      <td>(ROOT (S (NP (DT A) (NN girl)) (VP (VBZ is) (V...</td>\n",
       "      <td>(ROOT (S (NP (DT A) (NN girl)) (VP (VBZ is) (V...</td>\n",
       "      <td>A girl is playing with toys inside of a tub of...</td>\n",
       "      <td>A girl is taking a bath.</td>\n",
       "      <td>4838047403.jpg#3</td>\n",
       "      <td>4838047403.jpg#3r1n</td>\n",
       "      <td>neutral</td>\n",
       "      <td>entailment</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>entailment</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>785 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gold_label                             sentence1_binary_parse  \\\n",
       "145             -  ( ( ( A ( small group ) ) ( of church-goers ) ...   \n",
       "783             -  ( ( ( A woman ) ( wearing ( a ( pink hat ) ) )...   \n",
       "1562            -  ( man ( in ( ( red ( canada shirt ) ) ( standi...   \n",
       "2593            -  ( ( ( ( A man ) ( in ( a ( white jacket ) ) ) ...   \n",
       "2881            -  ( ( ( A ( swimmer 's ) ) hand ) ( ( is ( taken...   \n",
       "...           ...                                                ...   \n",
       "548159          -  ( ( Four people ) ( ( are ( ( selecting foods ...   \n",
       "548466          -  ( ( An ( outdoor ( market vendor ) ) ) ( ( ( r...   \n",
       "548920          -  ( ( One ( black dog ) ) ( ( chases ( ( ( anoth...   \n",
       "549427          -  ( ( The couple ) ( ( pauses ( atop ( a ( rocky...   \n",
       "549681          -  ( ( A girl ) ( ( is ( playing ( with ( toys ( ...   \n",
       "\n",
       "                                   sentence2_binary_parse  \\\n",
       "145     ( ( A choir ) ( ( performs ( in ( front ( of (...   \n",
       "783     ( ( The woman ) ( ( is ( wearing clothes ) ) ....   \n",
       "1562    ( ( Man standing ) ( with ( ( three men ) ( in...   \n",
       "2593    ( ( The man ) ( ( was ( ( playing crochet ) ( ...   \n",
       "2881              ( ( The swimmer ) ( ( is female ) . ) )   \n",
       "...                                                   ...   \n",
       "548159  ( ( The people ) ( ( are ( looking ( at ( ( th...   \n",
       "548466  ( ( A woman ) ( ( ( prepares ( for ( ( her day...   \n",
       "548920  ( There ( ( is ( ( grass ( on ( a ( road event...   \n",
       "549427  ( ( The couple ) ( ( is ( walking ( on ( a ( r...   \n",
       "549681  ( ( A girl ) ( ( is ( taking ( a bath ) ) ) . ) )   \n",
       "\n",
       "                                          sentence1_parse  \\\n",
       "145     (ROOT (S (NP (NP (DT A) (JJ small) (NN group))...   \n",
       "783     (ROOT (S (NP (NP (DT A) (NN woman)) (VP (VBG w...   \n",
       "1562    (ROOT (NP (NP (NN man)) (PP (IN in) (NP (NP (J...   \n",
       "2593    (ROOT (NP (NP (NP (DT A) (NN man)) (PP (IN in)...   \n",
       "2881    (ROOT (S (NP (NP (DT A) (NN swimmer) (POS 's))...   \n",
       "...                                                   ...   \n",
       "548159  (ROOT (S (NP (CD Four) (NNS people)) (VP (VBP ...   \n",
       "548466  (ROOT (S (NP (DT An) (JJ outdoor) (NN market) ...   \n",
       "548920  (ROOT (S (NP (CD One) (JJ black) (NN dog)) (VP...   \n",
       "549427  (ROOT (S (NP (DT The) (NN couple)) (VP (VBZ pa...   \n",
       "549681  (ROOT (S (NP (DT A) (NN girl)) (VP (VBZ is) (V...   \n",
       "\n",
       "                                          sentence2_parse  \\\n",
       "145     (ROOT (S (NP (DT A) (NN choir)) (VP (VBZ perfo...   \n",
       "783     (ROOT (S (NP (DT The) (NN woman)) (VP (VBZ is)...   \n",
       "1562    (ROOT (NP (NP (NN Man) (NN standing)) (PP (IN ...   \n",
       "2593    (ROOT (S (NP (DT The) (NN man)) (VP (VBD was) ...   \n",
       "2881    (ROOT (S (NP (DT The) (NN swimmer)) (VP (VBZ i...   \n",
       "...                                                   ...   \n",
       "548159  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...   \n",
       "548466  (ROOT (S (NP (DT A) (NN woman)) (VP (VBZ prepa...   \n",
       "548920  (ROOT (S (NP (EX There)) (VP (VBZ is) (NP (NP ...   \n",
       "549427  (ROOT (S (NP (DT The) (NN couple)) (VP (VBZ is...   \n",
       "549681  (ROOT (S (NP (DT A) (NN girl)) (VP (VBZ is) (V...   \n",
       "\n",
       "                                                sentence1  \\\n",
       "145     A small group of church-goers watch a choir pr...   \n",
       "783     A woman wearing a pink hat is looking at a pin...   \n",
       "1562    man in red canada shirt standing with three me...   \n",
       "2593    A man in a white jacket standing in front of a...   \n",
       "2881    A swimmer's hand is taken as he gets out of th...   \n",
       "...                                                   ...   \n",
       "548159   Four people are selecting foods from the buffet.   \n",
       "548466  An outdoor market vendor reaches up with a pol...   \n",
       "548920  One black dog chases another on grass nearby a...   \n",
       "549427           The couple pauses atop a rocky overlook.   \n",
       "549681  A girl is playing with toys inside of a tub of...   \n",
       "\n",
       "                                                sentence2         captionID  \\\n",
       "145            A choir performs in front of packed crowd.  2677109430.jpg#2   \n",
       "783                         The woman is wearing clothes.   226630666.jpg#1   \n",
       "1562    Man standing with three men in army uniform ne...   179172576.jpg#3   \n",
       "2593      The man was playing crochet with the two women.  4926115712.jpg#0   \n",
       "2881                               The swimmer is female.  7249180494.jpg#2   \n",
       "...                                                   ...               ...   \n",
       "548159  The people are looking at the things being ser...   307694396.jpg#1   \n",
       "548466  A woman prepares for her day of business by ge...  4921374490.jpg#2   \n",
       "548920  There is grass on a road eventhough it snowed ...  2281075738.jpg#0   \n",
       "549427        The couple is walking on a rockky overlook.   508958120.jpg#4   \n",
       "549681                           A girl is taking a bath.  4838047403.jpg#3   \n",
       "\n",
       "                     pairID         label1         label2         label3  \\\n",
       "145     2677109430.jpg#2r1c  contradiction  contradiction        neutral   \n",
       "783      226630666.jpg#1r1e     entailment     entailment        neutral   \n",
       "1562     179172576.jpg#3r1n        neutral  contradiction     entailment   \n",
       "2593    4926115712.jpg#0r1n        neutral  contradiction        neutral   \n",
       "2881    7249180494.jpg#2r1n        neutral        neutral  contradiction   \n",
       "...                     ...            ...            ...            ...   \n",
       "548159   307694396.jpg#1r1e     entailment  contradiction        neutral   \n",
       "548466  4921374490.jpg#2r1n        neutral  contradiction     entailment   \n",
       "548920  2281075738.jpg#0r1e     entailment  contradiction  contradiction   \n",
       "549427   508958120.jpg#4r1n        neutral  contradiction     entailment   \n",
       "549681  4838047403.jpg#3r1n        neutral     entailment  contradiction   \n",
       "\n",
       "               label4         label5  \n",
       "145           neutral            NaN  \n",
       "783           neutral  contradiction  \n",
       "1562    contradiction        neutral  \n",
       "2593    contradiction     entailment  \n",
       "2881    contradiction            NaN  \n",
       "...               ...            ...  \n",
       "548159     entailment            NaN  \n",
       "548466        neutral     entailment  \n",
       "548920     entailment            NaN  \n",
       "549427     entailment  contradiction  \n",
       "549681     entailment        neutral  \n",
       "\n",
       "[785 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf[traindf['gold_label']=='-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, tokens, pad_token='PAD', unk_token='UNK', unk_and_pad=True):\n",
    "        \"\"\"If we are creating a vocab of a finite set of labels, we don't need unk and pad tokens. \n",
    "        We then set unk_and_pad to False.\n",
    "        \"\"\"\n",
    "        if unk_and_pad:\n",
    "            self.tokens = tokens+[unk_token]\n",
    "            self.i2t = {i: t for i, t in enumerate(self.tokens, start=1)}\n",
    "            self.i2t[0] = pad_token\n",
    "            self.t2i = {v: k for k, v in self.i2t.items()}\n",
    "            self.tokens += [pad_token] \n",
    "        else:\n",
    "            self.tokens = tokens\n",
    "            self.i2t = {i: t for i, t in enumerate(self.tokens)}\n",
    "            self.t2i = {v: k for k, v in self.i2t.items()}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "    \n",
    "    def __getitem__(self, x):\n",
    "        if type(x) == str:\n",
    "            return self.t2i[x]\n",
    "        if type(x) == int:\n",
    "            return self.i2t[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLI_Dataset(Dataset):\n",
    "    def __init__(self, tsv_file,\n",
    "                 train=True,\n",
    "                 unk_token='UNK',\n",
    "                 pad_token='PAD',\n",
    "                 vocab=None,\n",
    "                 label_vocab=None):\n",
    "        \n",
    "        self.unk_token = unk_token\n",
    "        self.pad_token = pad_token\n",
    "        self.alldata = pd.read_csv(tsv_file, sep='\\t')\n",
    "        self.data = self.alldata[['sentence1', 'sentence2', 'gold_label']]\n",
    "        \n",
    "        self.gold_labels = [label for label in self.alldata['gold_label']]\n",
    "        self.premises = [list(tokenize(premise)) for premise in self.alldata['sentence1']]\n",
    "        self.hypotheses = [list(tokenize(hypothesis)) for hypothesis in self.alldata['sentence2']]\n",
    "        \n",
    "        if train:\n",
    "            self.tokens = list(set([token for line in self.premises for token in line]+[token for line in self.hypotheses for token in line]))\n",
    "            self.vocab = Vocab(self.tokens, pad_token=self.pad_token, unk_token=self.unk_token)    \n",
    "            self.label_vocab = Vocab(['neutral', 'contradiction', '-', 'entailment'], unk_and_pad=False)\n",
    "            self.int_premises = [[self.vocab[word] for word in seq] for seq in self.premises]\n",
    "            self.int_hypotheses = [[self.vocab[word] for word in seq] for seq in self.hypotheses]\n",
    "        \n",
    "        else:\n",
    "            self.vocab = vocab\n",
    "            self.label_vocab = label_vocab\n",
    "            self.int_premises = [[self.vocab[word] if word in self.vocab.t2i else self.vocab[self.unk_token] for word in seq] for seq in self.premises]\n",
    "            self.int_hypotheses = [[self.vocab[word] if word in self.vocab.t2i else self.vocab[self.unk_token] for word in seq] for seq in self.hypotheses]\n",
    "            \n",
    "        self.int_gold_labels = [self.label_vocab[label] for label in self.gold_labels]\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return (self.int_gold_labels[idx], self.int_premises[idx], self.int_hypotheses[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.int_gold_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nli_pad_fn(data):\n",
    "    p_len = max([len(x[1]) for x in data])\n",
    "    h_len = max([len(x[2]) for x in data])\n",
    "    padded_data = [(x[0], [w for w in x[1]+[0]*(p_len-len(x[1]))], [w for w in x[2]+[0]*(h_len-len(x[2]))]) for x in data]\n",
    "    return padded_data\n",
    "\n",
    "\n",
    "def dataloader(path_to_snli, batch_size, train=True, vocab=None, label_vocab=None):\n",
    "    dataset = NLI_Dataset(path_to_snli, train=train, vocab=vocab, label_vocab=label_vocab)\n",
    "    dataloader = DataLoader(dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            collate_fn=nli_pad_fn)\n",
    "    if train==True:\n",
    "        return dataloader, dataset.vocab, dataset.label_vocab\n",
    "    else:\n",
    "        return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_index = 0\n",
      "Batch size: 2\n",
      "(1, [3815, 3464, 156, 4228, 6561, 1897, 4413, 1450, 6528, 1803, 4228, 362, 156, 2930, 5021, 6883, 6545, 6515, 6141, 3457, 217, 634, 225, 3457, 2930], [4693, 156, 2116, 4278, 6628, 6800, 1803, 6003, 0])\n",
      "premise length: 25\n",
      "hypothesis length: 9\n",
      "(0, [3815, 3351, 5025, 156, 1803, 2875, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3815, 3351, 1450, 5430, 3457, 4047, 5729, 1803, 4108])\n",
      "premise length: 25\n",
      "hypothesis length: 9\n"
     ]
    }
   ],
   "source": [
    "iterator, vocab, labels = dataloader(test_path, 2)\n",
    "print('pad_index =', vocab.t2i['PAD'])\n",
    "for i, batch in enumerate(iterator):\n",
    "    print('Batch size:', len(batch)) \n",
    "    for example in batch:\n",
    "        print(example)\n",
    "        print('premise length:', len(example[1]))\n",
    "        print('hypothesis length:', len(example[2]))\n",
    "  # Only look at first batch.\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we'll build the model for predicting the relationship between H and P.\n",
    "\n",
    "We will process each sentence using an LSTM. Then, we will construct some representation of the sentence. When we have a representation for H and P, we will combine them into one vector which we can use to predict the relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train a model described in [2], the BiLSTM with max-pooling model. The procedure for the model is roughly:\n",
    "\n",
    "    1) Encode the Hypothesis and the Premise using one shared bidirectional LSTM (or two different LSTMS)\n",
    "    2) Perform max over the tokens in the premise and the hypothesis\n",
    "    3) Combine the encoded premise and encoded hypothesis into one representation\n",
    "    4) Predict the relationship "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a representation of a sentence\n",
    "\n",
    "Let's first consider step 2 where we perform max/mean pooling. There is a function in pytorch for this, but we'll implement it from scratch. \n",
    "\n",
    "Let's consider the general case, what we want to do for these methods is apply some function $f$ along dimension $i$, and we want to do this for all $i$'s. As an example we consider the matrix S with size ``(N, D)`` where N is the number of words and D the number of dimensions:\n",
    "\n",
    "$S = \\begin{bmatrix}\n",
    "    s_{11} & s_{12} & s_{13} & \\dots  & s_{1d} \\\\\n",
    "    s_{21} & s_{22} & s_{23} & \\dots  & s_{2d} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    s_{n1} & s_{n2} & s_{n3} & \\dots  & s_{nd}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "What we want to do is apply our function $f$ on each dimension, taking the input $s_{1d}, s_{2d}, ..., s_{nd}$ and generating the output $x_d$. \n",
    "\n",
    "You will implement both the max pooling method. When performing max-pooling, $max$ will be the function which selects a _maximum_ value from a vector and $x$ is the output, thus for each dimension $d$ in our output $x$ we get:\n",
    "\n",
    "\\begin{equation}\n",
    "    x_d = max(s_{1d}, s_{2d}, ..., s_{nd})\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "This operation will reduce a batch of size ``(batch_size, num_words, dimensions)`` to ``(batch_size, dimensions)`` meaning that we now have created a sentence representation based on the content of the words representations in the sentence. \n",
    "\n",
    "Create a function that takes as input a tensor of size ``(batch_size, num_words, dimensions)`` then performs max pooling and returns the result (the output should be of size: ```(batch_size, dimensions)```). [**4 Marks**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling(input_tensor):\n",
    "    output_tensor = torch.max(input_tensor, 1)[0] \n",
    "    return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 3, 2]), torch.Size([4, 2]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand((4,3,2))\n",
    "a.shape, pooling(a).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining sentence representations\n",
    "\n",
    "Next, we need to combine the premise and hypothesis into one representation. We will do this by concatenating four tensors (the final size of our tensor $X$ should be ``(batch_size, 4d)`` where ``d`` is the number of dimensions that you use): \n",
    "\n",
    "$$X = [P; H; |P-H|; P \\cdot H]$$\n",
    "\n",
    "Here, what we do is concatenating P, H, P times H, and the absolute value of P minus H, then return the result.\n",
    "\n",
    "Implement the function. **[2 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_premise_and_hypothesis(premise, hypothesis):\n",
    "    p_minus_h = torch.sub(premise, hypothesis)\n",
    "    p_times_h = torch.stack([torch.mul(premise[i],hypothesis[i])for i in range(len(premise))])\n",
    "    output = torch.cat((premise, hypothesis, p_minus_h, p_times_h), 1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[90, 46,  5, 28],\n",
       "         [64, 17, 86, 31]]),\n",
       " tensor([[65, 80,  6, 34],\n",
       "         [96, 23, 62,  8]]),\n",
       " tensor([[5850, 3680,   30,  952],\n",
       "         [6144,  391, 5332,  248]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randint(100, (2,4)).long()\n",
    "b = torch.randint(100, (2,4)).long()\n",
    "c = torch.stack([torch.mul(a[i],b[i])for i in range(len(a))])\n",
    "a,b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4, 4]), torch.Size([2, 1, 4]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randint(100, (2,4)).unsqueeze(dim=1).long()\n",
    "b = torch.randint(100, (2,4)).unsqueeze(dim=1).long()\n",
    "torch.bmm(torch.transpose(a,1,2),b).shape, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 2]), torch.Size([4, 2]), torch.Size([4, 8]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand((4,3,2))\n",
    "b = torch.rand((4,3,2))\n",
    "ap = pooling(a)\n",
    "bp = pooling(b)\n",
    "c = combine_premise_and_hypothesis(ap, bp)\n",
    "ap.shape, bp.shape, c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model\n",
    "\n",
    "Finally, we can build the model according to the procedure given previously by using the functions we defined above. Additionaly, in the model you should use *dropout*. For efficiency purposes, it's acceptable to only train the model with either max or mean pooling. \n",
    "\n",
    "Implement the model [**6 marks**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNLIModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dims, hidden_dims, n_labels, pad_index=0, dropout=0.1):\n",
    "        super(SNLIModel, self).__init__()\n",
    "        \n",
    "        self.pad_index = pad_index\n",
    "        self.embeddings = nn.Embedding(vocab_size, \n",
    "                                       embedding_dims, \n",
    "                                       padding_idx=pad_index)\n",
    "        self.rnn = nn.LSTM(embedding_dims, \n",
    "                           hidden_dims, \n",
    "                           bidirectional=True,\n",
    "                           batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(hidden_dims*8, n_labels) \n",
    "        \n",
    "        #  multilayer perceptron?\n",
    "        \n",
    "    def forward(self, premise, hypothesis):\n",
    "        p_embedded = self.embeddings(premise)\n",
    "        h_embedded = self.embeddings(hypothesis)\n",
    "        \n",
    "        p = self.dropout(p_embedded)  \n",
    "        h = self.dropout(h_embedded)  \n",
    "        \n",
    "        p, _ = self.rnn(p)\n",
    "        h, _ = self.rnn(h)\n",
    "         \n",
    "        p_pooled = pooling(p)\n",
    "        h_pooled = pooling(h)\n",
    "        \n",
    "        ph_representation = combine_premise_and_hypothesis(p_pooled,h_pooled)\n",
    "        predictions = self.classifier(ph_representation)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, implement the training and testing of the model. SNLI can take a very long time to train, so I suggest you only run it for one or two epochs. **[2 marks]** \n",
    "\n",
    "**Tip for efficiency:** *when developing your model, try training and testing the model on one batch (for each epoch) of data to make sure everything works! It's very annoying if you train for N epochs to find out that something went wrong when testing the model, or to find that something goes wrong when moving from epoch 0 to epoch 1.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters:\n",
    "epochs = 3\n",
    "batch_size = 4\n",
    "embedding_dims = 32\n",
    "hidden_dims = 32\n",
    "dropout = 0.1\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data:\n",
    "train_iter, vocab, label_vocab = dataloader(dev_path, batch_size)  # fix train corpus, there is some formatting error making the tokenizer crash\n",
    "test_iter = dataloader(test_path, batch_size, train=False, vocab=vocab, label_vocab=label_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/gussodato@GU.GU.SE/.local/lib/python3.10/site-packages (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11 in /home/gussodato@GU.GU.SE/.local/lib/python3.10/site-packages (from nvidia-cudnn-cu11==8.5.0.96) (11.10.3.66)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.10/site-packages (from nvidia-cublas-cu11->nvidia-cudnn-cu11==8.5.0.96) (0.40.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3.10/site-packages (from nvidia-cublas-cu11->nvidia-cudnn-cu11==8.5.0.96) (59.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nvidia-cudnn-cu11==8.5.0.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SNLIModel(len(vocab), embedding_dims, hidden_dims, len(label_vocab), dropout=dropout).to(device)\n",
    "loss_function = nn.CrossEntropyLoss(reduction='mean').to(device) #  cross entropy reduction=mean bc sum will mean error is very large, might overcorrect? basically same as batch loss. also reduction=mean is default anyway\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c8be504f924c8596dc6d24199fb3e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.322612\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i, batch in enumerate(train_iter):\n",
    "         \n",
    "        gold_labels = torch.Tensor([example[0] for example in batch]).long().to(device)\n",
    "        premises = torch.Tensor([example[1] for example in batch]).long().to(device)\n",
    "        hypotheses = torch.Tensor([example[2] for example in batch]).long().to(device)\n",
    "                  \n",
    "        output = model(premises, hypotheses)\n",
    "                  \n",
    "        loss = loss_function(output, gold_labels)\n",
    "                  \n",
    "        optimizer.step()\n",
    "                  \n",
    "        optimizer.zero_grad()             \n",
    "                  \n",
    "        total_loss += loss.item()\n",
    "                        \n",
    "        \n",
    "        if (i%100) == 0:\n",
    "            print('total_loss:', round(total_loss / (i + 1), 4), end='\\r')\n",
    "            \n",
    "\n",
    "# save trained model\n",
    "# pickle.dump(model, open('model.pickle', 'wb'))\n",
    "    \n",
    "# test model after all epochs are completed\n",
    "accuracies = []\n",
    "for batch in test_iter:\n",
    "    gold_labels = [example[0] for example in batch]\n",
    "    premises = torch.Tensor([example[1] for example in batch]).long().to(device)\n",
    "    hypotheses = torch.Tensor([example[2] for example in batch]).long().to(device)\n",
    "    output = model(premises, hypotheses).cpu().numpy(force=True)\n",
    "    model_predictions = [np.argmax(output[i]) for i in range(len(batch))]\n",
    "    batch_accuracies = [int(gold_labels[i] == model_predictions[i]) for i in range(len(batch))]\n",
    "    accuracies.extend(batch_accuracies)\n",
    "\n",
    "print('accuracy:', sum(accuracies)/len(accuracies))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggest a _baseline_ that we can compare our model against **[2 marks]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer should go here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggest some ways (other than using a baseline) in which we can analyse the models performance **[4 marks]**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer should go here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggest some ways to improve the model **[3 marks]**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer should go here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readings\n",
    "\n",
    "[1] Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. 2015. A large annotated corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP). \n",
    "\n",
    "[2] Conneau, A., Kiela, D., Schwenk, H., Barrault, L., & Bordes, A. (2017). Supervised learning of universal sentence representations from natural language inference data. arXiv preprint arXiv:1705.02364."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statement of contribution\n",
    "\n",
    "Briefly state how many times you have met for discussions, who was present, to what degree each member contributed to the discussion and the final answers you are submitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marks\n",
    "\n",
    "This assignment has a total of 23 marks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
